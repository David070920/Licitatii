name: Health Monitoring

on:
  schedule:
    - cron: '*/15 * * * *'  # Every 15 minutes
  workflow_dispatch:
    inputs:
      check_type:
        description: 'Type of health check'
        required: false
        default: 'full'
        type: choice
        options:
        - full
        - quick
        - performance_only

env:
  TIMEOUT_SECONDS: 30

jobs:
  health-check:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Check Frontend Health
      id: frontend
      env:
        FRONTEND_URL: ${{ vars.FRONTEND_URL || 'https://procurement-platform.me' }}
      run: |
        echo "Checking frontend at $FRONTEND_URL"
        
        # Check if frontend is accessible
        response_code=$(curl -s -o /dev/null -w "%{http_code}" --max-time ${{ env.TIMEOUT_SECONDS }} "$FRONTEND_URL")
        response_time=$(curl -s -o /dev/null -w "%{time_total}" --max-time ${{ env.TIMEOUT_SECONDS }} "$FRONTEND_URL")
        
        echo "response_code=$response_code" >> $GITHUB_OUTPUT
        echo "response_time=$response_time" >> $GITHUB_OUTPUT
        
        if [ $response_code -eq 200 ]; then
          echo "status=healthy" >> $GITHUB_OUTPUT
          echo "‚úÖ Frontend is healthy (${response_time}s)"
        else
          echo "status=unhealthy" >> $GITHUB_OUTPUT
          echo "‚ùå Frontend returned HTTP $response_code"
        fi
    
    - name: Check API Health
      id: api
      env:
        API_BASE_URL: ${{ vars.API_BASE_URL || 'https://api.procurement-platform.me' }}
      run: |
        echo "Checking API at $API_BASE_URL"
        
        # Check basic health endpoint
        response_code=$(curl -s -o /dev/null -w "%{http_code}" --max-time ${{ env.TIMEOUT_SECONDS }} "$API_BASE_URL/health")
        response_time=$(curl -s -o /dev/null -w "%{time_total}" --max-time ${{ env.TIMEOUT_SECONDS }} "$API_BASE_URL/health")
        
        echo "response_code=$response_code" >> $GITHUB_OUTPUT
        echo "response_time=$response_time" >> $GITHUB_OUTPUT
        
        if [ $response_code -eq 200 ]; then
          echo "status=healthy" >> $GITHUB_OUTPUT
          echo "‚úÖ API is healthy (${response_time}s)"
        else
          echo "status=unhealthy" >> $GITHUB_OUTPUT
          echo "‚ùå API returned HTTP $response_code"
        fi
    
    - name: Check Database Connectivity
      id: database
      env:
        API_BASE_URL: ${{ vars.API_BASE_URL || 'https://api.procurement-platform.me' }}
      run: |
        echo "Checking database connectivity"
        
        # Check database health endpoint
        response_code=$(curl -s -o /dev/null -w "%{http_code}" --max-time ${{ env.TIMEOUT_SECONDS }} "$API_BASE_URL/health/db")
        response_time=$(curl -s -o /dev/null -w "%{time_total}" --max-time ${{ env.TIMEOUT_SECONDS }} "$API_BASE_URL/health/db")
        
        echo "response_code=$response_code" >> $GITHUB_OUTPUT
        echo "response_time=$response_time" >> $GITHUB_OUTPUT
        
        if [ $response_code -eq 200 ]; then
          echo "status=healthy" >> $GITHUB_OUTPUT
          echo "‚úÖ Database is healthy (${response_time}s)"
        else
          echo "status=unhealthy" >> $GITHUB_OUTPUT
          echo "‚ùå Database check returned HTTP $response_code"
        fi
    
    - name: Check Redis Connectivity
      id: redis
      env:
        API_BASE_URL: ${{ vars.API_BASE_URL || 'https://api.procurement-platform.me' }}
      run: |
        echo "Checking Redis connectivity"
        
        # Check Redis health endpoint
        response_code=$(curl -s -o /dev/null -w "%{http_code}" --max-time ${{ env.TIMEOUT_SECONDS }} "$API_BASE_URL/health/redis" 2>/dev/null || echo "000")
        response_time=$(curl -s -o /dev/null -w "%{time_total}" --max-time ${{ env.TIMEOUT_SECONDS }} "$API_BASE_URL/health/redis" 2>/dev/null || echo "0")
        
        echo "response_code=$response_code" >> $GITHUB_OUTPUT
        echo "response_time=$response_time" >> $GITHUB_OUTPUT
        
        if [ $response_code -eq 200 ]; then
          echo "status=healthy" >> $GITHUB_OUTPUT
          echo "‚úÖ Redis is healthy (${response_time}s)"
        elif [ $response_code -eq 404 ]; then
          echo "status=not_implemented" >> $GITHUB_OUTPUT
          echo "‚ÑπÔ∏è Redis health endpoint not implemented"
        else
          echo "status=unhealthy" >> $GITHUB_OUTPUT
          echo "‚ùå Redis check returned HTTP $response_code"
        fi
    
    - name: Performance Benchmarks
      id: performance
      env:
        FRONTEND_URL: ${{ vars.FRONTEND_URL || 'https://procurement-platform.me' }}
        API_BASE_URL: ${{ vars.API_BASE_URL || 'https://api.procurement-platform.me' }}
      run: |
        echo "Running performance benchmarks"
        
        # Frontend performance
        frontend_time=$(curl -s -o /dev/null -w "%{time_total}" --max-time 10 "$FRONTEND_URL")
        
        # API performance  
        api_time=$(curl -s -o /dev/null -w "%{time_total}" --max-time 10 "$API_BASE_URL/health")
        
        # API endpoints performance
        tenders_time=$(curl -s -o /dev/null -w "%{time_total}" --max-time 10 "$API_BASE_URL/api/v1/tenders?limit=1" || echo "999")
        
        echo "frontend_time=$frontend_time" >> $GITHUB_OUTPUT
        echo "api_time=$api_time" >> $GITHUB_OUTPUT
        echo "tenders_time=$tenders_time" >> $GITHUB_OUTPUT
        
        # Performance warnings
        if (( $(echo "$frontend_time > 3.0" | bc -l 2>/dev/null || echo 0) )); then
          echo "‚ö†Ô∏è Frontend response time: ${frontend_time}s (slow)"
        else
          echo "‚úÖ Frontend response time: ${frontend_time}s"
        fi
        
        if (( $(echo "$api_time > 2.0" | bc -l 2>/dev/null || echo 0) )); then
          echo "‚ö†Ô∏è API response time: ${api_time}s (slow)"
        else
          echo "‚úÖ API response time: ${api_time}s"
        fi
        
        if (( $(echo "$tenders_time > 5.0" | bc -l 2>/dev/null || echo 0) )); then
          echo "‚ö†Ô∏è Tenders endpoint response time: ${tenders_time}s (slow)"
        else
          echo "‚úÖ Tenders endpoint response time: ${tenders_time}s"
        fi
    
    - name: SSL Certificate Check
      id: ssl
      env:
        FRONTEND_URL: ${{ vars.FRONTEND_URL || 'https://procurement-platform.me' }}
        API_BASE_URL: ${{ vars.API_BASE_URL || 'https://api.procurement-platform.me' }}
      run: |
        echo "Checking SSL certificates"
        
        # Extract domains from URLs
        frontend_domain=$(echo "$FRONTEND_URL" | sed 's|https\?://||' | cut -d'/' -f1)
        api_domain=$(echo "$API_BASE_URL" | sed 's|https\?://||' | cut -d'/' -f1)
        
        check_ssl() {
          local domain=$1
          local name=$2
          
          if command -v openssl >/dev/null 2>&1; then
            expiry_date=$(echo | openssl s_client -servername "$domain" -connect "$domain:443" 2>/dev/null | openssl x509 -noout -dates 2>/dev/null | grep notAfter | cut -d= -f2)
            
            if [ -n "$expiry_date" ]; then
              expiry_timestamp=$(date -d "$expiry_date" +%s 2>/dev/null || date -j -f "%b %d %T %Y %Z" "$expiry_date" +%s 2>/dev/null || echo 0)
              current_timestamp=$(date +%s)
              days_until_expiry=$(( (expiry_timestamp - current_timestamp) / 86400 ))
              
              echo "${name}_ssl_days=$days_until_expiry" >> $GITHUB_OUTPUT
              
              if [ $days_until_expiry -lt 30 ]; then
                echo "‚ö†Ô∏è $name SSL certificate expires in $days_until_expiry days"
                echo "${name}_ssl_status=warning" >> $GITHUB_OUTPUT
              elif [ $days_until_expiry -lt 0 ]; then
                echo "‚ùå $name SSL certificate has expired"
                echo "${name}_ssl_status=expired" >> $GITHUB_OUTPUT
              else
                echo "‚úÖ $name SSL certificate valid for $days_until_expiry days"
                echo "${name}_ssl_status=valid" >> $GITHUB_OUTPUT
              fi
            else
              echo "‚ùå Could not check $name SSL certificate"
              echo "${name}_ssl_status=error" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ÑπÔ∏è OpenSSL not available, skipping SSL check for $name"
            echo "${name}_ssl_status=skipped" >> $GITHUB_OUTPUT
          fi
        }
        
        check_ssl "$frontend_domain" "frontend"
        check_ssl "$api_domain" "api"
    
    - name: Generate Health Report
      id: report
      run: |
        echo "Generating health report..."
        
        # Count healthy services
        healthy_count=0
        total_count=4
        
        [ "${{ steps.frontend.outputs.status }}" = "healthy" ] && ((healthy_count++))
        [ "${{ steps.api.outputs.status }}" = "healthy" ] && ((healthy_count++))
        [ "${{ steps.database.outputs.status }}" = "healthy" ] && ((healthy_count++))
        [ "${{ steps.redis.outputs.status }}" = "healthy" ] || [ "${{ steps.redis.outputs.status }}" = "not_implemented" ] && ((healthy_count++))
        
        health_percentage=$((healthy_count * 100 / total_count))
        
        echo "healthy_count=$healthy_count" >> $GITHUB_OUTPUT
        echo "total_count=$total_count" >> $GITHUB_OUTPUT
        echo "health_percentage=$health_percentage" >> $GITHUB_OUTPUT
        
        if [ $health_percentage -eq 100 ]; then
          echo "overall_status=healthy" >> $GITHUB_OUTPUT
          echo "‚úÖ All systems operational ($healthy_count/$total_count)"
        elif [ $health_percentage -ge 75 ]; then
          echo "overall_status=degraded" >> $GITHUB_OUTPUT
          echo "‚ö†Ô∏è Some systems degraded ($healthy_count/$total_count)"
        else
          echo "overall_status=unhealthy" >> $GITHUB_OUTPUT
          echo "‚ùå Multiple systems down ($healthy_count/$total_count)"
        fi
    
    - name: Send Alert if Unhealthy
      if: steps.report.outputs.overall_status != 'healthy'
      env:
        SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK_URL }}
      run: |
        # Determine alert color
        case "${{ steps.report.outputs.overall_status }}" in
          "degraded") color="warning" ;;
          "unhealthy") color="danger" ;;
          *) color="good" ;;
        esac
        
        # Build status fields
        status_fields="[
          {\"title\": \"Frontend\", \"value\": \"${{ steps.frontend.outputs.status }} (${{ steps.frontend.outputs.response_time }}s)\", \"short\": true},
          {\"title\": \"API\", \"value\": \"${{ steps.api.outputs.status }} (${{ steps.api.outputs.response_time }}s)\", \"short\": true},
          {\"title\": \"Database\", \"value\": \"${{ steps.database.outputs.status }} (${{ steps.database.outputs.response_time }}s)\", \"short\": true},
          {\"title\": \"Redis\", \"value\": \"${{ steps.redis.outputs.status }}\", \"short\": true},
          {\"title\": \"Health Score\", \"value\": \"${{ steps.report.outputs.health_percentage }}% (${{ steps.report.outputs.healthy_count }}/${{ steps.report.outputs.total_count }})\", \"short\": true},
          {\"title\": \"Check Time\", \"value\": \"$(date -u +%Y-%m-%d\ %H:%M\ UTC)\", \"short\": true}
        ]"
        
        curl -X POST -H 'Content-type: application/json' \
          --data "{
            \"text\": \"üö® Health Check Alert: Romanian Procurement Platform\",
            \"attachments\": [
              {
                \"color\": \"$color\",
                \"title\": \"System Health Report\",
                \"text\": \"Status: ${{ steps.report.outputs.overall_status }}\",
                \"fields\": $status_fields
              }
            ]
          }" \
          $SLACK_WEBHOOK || echo "Failed to send alert"
    
    - name: Create Issue on Repeated Failures
      if: steps.report.outputs.overall_status == 'unhealthy'
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Check if there's already an open health issue
        existing_issue=$(gh issue list --label "health-alert" --state open --json number --jq '.[0].number // empty')
        
        if [ -z "$existing_issue" ]; then
          # Create new issue
          gh issue create \
            --title "üö® Platform Health Alert - Multiple Systems Down" \
            --body "**Health Check Failed**
          
          **Status Summary:**
          - Frontend: ${{ steps.frontend.outputs.status }} (${{ steps.frontend.outputs.response_code }})
          - API: ${{ steps.api.outputs.status }} (${{ steps.api.outputs.response_code }})
          - Database: ${{ steps.database.outputs.status }} (${{ steps.database.outputs.response_code }})
          - Redis: ${{ steps.redis.outputs.status }} (${{ steps.redis.outputs.response_code }})
          
          **Performance:**
          - Frontend Response Time: ${{ steps.performance.outputs.frontend_time }}s
          - API Response Time: ${{ steps.performance.outputs.api_time }}s
          - Tenders Endpoint: ${{ steps.performance.outputs.tenders_time }}s
          
          **Next Steps:**
          1. Check Railway dashboard for service status
          2. Review application logs
          3. Verify database connectivity
          4. Check for any ongoing incidents
          
          **Auto-generated by Health Monitoring**
          Time: $(date -u +%Y-%m-%d\ %H:%M\ UTC)" \
            --label "health-alert,urgent" \
            --assignee "@me"
          
          echo "Created new health alert issue"
        else
          echo "Health alert issue already exists: #$existing_issue"
          
          # Add comment to existing issue
          gh issue comment "$existing_issue" \
            --body "**Health Check Update** - $(date -u +%Y-%m-%d\ %H:%M\ UTC)
          
          Still experiencing issues:
          - Frontend: ${{ steps.frontend.outputs.status }}
          - API: ${{ steps.api.outputs.status }}
          - Database: ${{ steps.database.outputs.status }}
          - Redis: ${{ steps.redis.outputs.status }}"
        fi
    
    - name: Close Issue on Recovery
      if: steps.report.outputs.overall_status == 'healthy'
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Close any open health alert issues
        open_issues=$(gh issue list --label "health-alert" --state open --json number --jq '.[].number')
        
        for issue_number in $open_issues; do
          gh issue comment "$issue_number" \
            --body "‚úÖ **Health Check Recovered** - $(date -u +%Y-%m-%d\ %H:%M\ UTC)
          
          All systems are now operational:
          - Frontend: ‚úÖ Healthy (${{ steps.frontend.outputs.response_time }}s)
          - API: ‚úÖ Healthy (${{ steps.api.outputs.response_time }}s)
          - Database: ‚úÖ Healthy (${{ steps.database.outputs.response_time }}s)
          - Redis: ‚úÖ Healthy
          
          Auto-closing this issue."
          
          gh issue close "$issue_number"
          echo "Closed health alert issue #$issue_number"
        done